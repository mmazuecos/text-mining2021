{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "039b8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as fn\n",
    "import torch.optim as optim\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import mlflow\n",
    "import gzip\n",
    "import tempfile\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.nn import DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d425e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "QTYPES = ['<color>', '<shape>', '<spatial>', 'other', '<action>', 'object', '<texture>', '<size>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c86a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWQtypeDataset(Dataset):\n",
    "    def __init__(self, file_path, embs, unk_emb, successful_only=False):\n",
    "        self.dataset = pd.read_csv(file_path)\n",
    "        self.dataset['qtype'].fillna('<other>', inplace=True)\n",
    "        self.dataset['question'] = self.dataset['question'].apply(lambda x: x.strip().lower())\n",
    "        self.embs = embs\n",
    "        self.unk_emb = unk_emb\n",
    "        \n",
    "    def vectorize_cat(self, x):\n",
    "        qtype = x[1:-1].replace('\\'', '').split(', ')\n",
    "        if qtype == 'super-category':\n",
    "            qtype = 'object'\n",
    "        # Marco con 1 los qtypes que sí están\n",
    "        qtype_vector = [int(q in qtype) for q in QTYPES]\n",
    "        return qtype_vector\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        datapoint = self.dataset.iloc[idx]\n",
    "        qtype = self.vectorize_cat(datapoint.qtype)\n",
    "        words = datapoint.question.split()\n",
    "        sent_embs = [self.embs[w] if w in self.embs.keys() else self.unk_emb for w in words]\n",
    "        new_entry = np.array(sent_embs).sum(axis=0)\n",
    "\n",
    "        output = {'qid': datapoint.question_id,\n",
    "                  'question': np.array(sent_embs).sum(axis=0),\n",
    "                  'qtype': np.asarray(qtype)}\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fd0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(corpus, embeddings_dict, unk_emb):\n",
    "    new_data = []\n",
    "    vocab = []\n",
    "    skipped = []\n",
    "    for i, entry in enumerate(corpus):\n",
    "        words = entry.strip().split()\n",
    "        if len(words) < 1:\n",
    "            print('WARNING: skipped empty question')\n",
    "            skipped.append(i)\n",
    "            continue\n",
    "        # remove the last ? sign\n",
    "        last = words[-1]\n",
    "        words = words[:-1] + [last[:-1], '?']\n",
    "        # append tokens to vocabulary\n",
    "        vocab += words\n",
    "        # form new data\n",
    "        sent_embs = [embeddings_dict[w] if w in embeddings_dict.keys() else unk_emb for w in words]\n",
    "        new_entry = np.array(sent_embs).sum(axis=0)\n",
    "        new_data.append(new_entry)\n",
    "    return np.array(new_data), skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292e5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBS = \"glove.6B.50d.txt.gz\"\n",
    "embeddings_dict_50d = {}\n",
    "with gzip.open(PRETRAINED_EMBS, \"rt\") as fh:\n",
    "    for line in fh:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict_50d[word] = vector\n",
    "UNK_EMB_50d = np.random.rand(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527afbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict_50d['<UNK>'] = UNK_EMB_50d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d767f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QtypeClassifierA(nn.Module):\n",
    "    \"\"\"\n",
    "    Uses the best config from the Clustering experiments\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 8),\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        output = self.mlp(data)\n",
    "        if not self.training:\n",
    "            output = torch.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06324f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = GWQtypeDataset('guesswhat.train.csv.gz', embeddings_dict_50d, UNK_EMB_50d, False)\n",
    "valid_data = GWQtypeDataset('guesswhat.valid.csv.gz', embeddings_dict_50d, UNK_EMB_50d, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f4d65d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/05 20:48:32 INFO mlflow.tracking.fluent: Experiment with name 'ClassifierA' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedcf127f56b47efa0f38fb69c910660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c72f90abbc141659cc2b82cda196781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31318eaabf2943b2b051eae9a20054dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5837d60848bb4850a94ac8c520a99c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020446bf050348a489270f4de3b988cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1d84653e174e40b6494abc8e90b398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcac9aa90d14e76a59b7299d73c1da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a9765288c24188a7a9ac7572b9618b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd32017a42f74cf6ba0b2f8c43b2d018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc75cd88325748b382c08d9d83373874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3e72e3d02246848dc242023a32cd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset=train_data,\n",
    "                        batch_size=256,\n",
    "                        shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset=valid_data,\n",
    "                              batch_size=256,\n",
    "                              shuffle=True)\n",
    "\n",
    "mlflow.set_experiment(\"ClassifierA\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_name\", \"mlp_best_feature\")\n",
    "    mlflow.log_params({\n",
    "        \"embedding\": 'aggregated_glove50d',\n",
    "    })\n",
    "    model = QtypeClassifierA()\n",
    "    lossfn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    for epoch in trange(5):\n",
    "        model.train()\n",
    "        running_loss = []\n",
    "        for idx, batch in enumerate(tqdm(dataloader)):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch[\"question\"].float())\n",
    "            loss_value = lossfn(output, batch[\"qtype\"].float())\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss_value.item())        \n",
    "        mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in tqdm(dataloader_valid):\n",
    "            output = model(batch[\"question\"].float())\n",
    "            running_loss.append(\n",
    "                lossfn(output, batch[\"qtype\"].float()).item()\n",
    "            )\n",
    "            targets.extend(batch[\"qtype\"].numpy())\n",
    "            predictions.extend(output.squeeze().detach().numpy())\n",
    "        mlflow.log_metric(\"validation_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        mlflow.log_metric(\"validation_avp\", average_precision_score(targets, predictions), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5c6065e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d58d47783fc4426a5bb1b363e2f8756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    question_ids = []\n",
    "    for batch in tqdm(dataloader_valid):\n",
    "        output = model(batch[\"question\"].float())\n",
    "        targets.extend(batch[\"qtype\"].float().numpy())\n",
    "        predictions.extend(output.squeeze().detach().numpy())\n",
    "        question_ids.extend(batch[\"qid\"].numpy())\n",
    "    pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(\n",
    "        f\"{tmpdirname}/predictions.csv.gz\", index=False\n",
    "    )\n",
    "    mlflow.log_artifact(f\"{tmpdirname}/predictions.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5740f4d",
   "metadata": {},
   "source": [
    "## Second approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "918d4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWQtypeDatasetRNN(Dataset):\n",
    "    def __init__(self, file_path, vocab, max_len=20, successful_only=False):\n",
    "        self.dataset = pd.read_csv(file_path)\n",
    "        self.dataset['qtype'].fillna('<other>', inplace=True)\n",
    "        self.dataset['question'] = self.dataset['question'].apply(lambda x: x.strip().lower())\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def vectorize_cat(self, x):\n",
    "        qtype = x[1:-1].replace('\\'', '').split(', ')\n",
    "        if qtype == 'super-category':\n",
    "            qtype = 'object'\n",
    "        # Marco con 1 los qtypes que sí están\n",
    "        qtype_vector = [int(q in qtype) for q in QTYPES]\n",
    "        return qtype_vector\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tok2id = self.vocab['tok2id']\n",
    "        datapoint = self.dataset.iloc[idx]\n",
    "        qtype = self.vectorize_cat(datapoint.qtype)\n",
    "        words = datapoint.question.split()\n",
    "        sent_embs = [tok2id[w] if w in tok2id.keys() else tok2id['UNK'] for w in words]\n",
    "        if len(sent_embs) < self.max_len:\n",
    "            sent_embs.extend([tok2id['PADDING'] for _ in range(self.max_len - len(sent_embs))])\n",
    "        elif len(sent_embs) > self.max_len:\n",
    "            sent_embs = sent_embs[:self.max_len]\n",
    "            \n",
    "        assert(len(sent_embs) == self.max_len)\n",
    "        output = {'qid': datapoint.question_id,\n",
    "                  'question': np.array(sent_embs),\n",
    "                  'qtype': np.array(qtype)}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4158c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBS = \"glove.6B.50d.txt.gz\"\n",
    "embeddings_dict_50d = OrderedDict()\n",
    "embeddings_dict_50d['PADDING'] = np.zeros(50)\n",
    "embeddings_dict_50d['UNK'] = np.random.rand(50)\n",
    "with gzip.open(PRETRAINED_EMBS, \"rt\") as fh:\n",
    "    for line in fh:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict_50d[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31208873",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict_50d['PADDING'] = np.zeros(50).astype(np.float32)\n",
    "embeddings_dict_50d['UNK'] = np.random.rand(50).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "822fc493",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'tok2id': {k:i for i,k in enumerate(embeddings_dict_50d)},\n",
    "         'id2tok': {i:k for i,k in enumerate(embeddings_dict_50d)}}\n",
    "\n",
    "emb_matrix = np.array(list(embeddings_dict_50d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "118fc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = GWQtypeDatasetRNN('guesswhat.train.csv.gz', vocab)\n",
    "valid_data = GWQtypeDatasetRNN('guesswhat.valid.csv.gz', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c3fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QtypeClassifierB(nn.Module):\n",
    "    \"\"\"\n",
    "    Uses an GRU and word embeddings for question classification\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_matrix):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(emb_matrix),\n",
    "                                                      freeze=True,\n",
    "                                                      padding_idx=0)\n",
    "        self.rnn = nn.GRU(50, 128, batch_first=True)\n",
    "        self.out_layer = nn.Linear(128, 8)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data)\n",
    "        gru_out, _ = self.rnn(x)\n",
    "        # Me quedo solo con el último estado oculto\n",
    "        output = self.out_layer(fn.relu(gru_out[:,-1,:]))\n",
    "        if not self.training:\n",
    "            output = torch.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20217d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QtypeClassifierB(\n",
       "  (embedding): Embedding(400002, 50, padding_idx=0)\n",
       "  (rnn): GRU(50, 128, batch_first=True)\n",
       "  (out_layer): Linear(in_features=128, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "model = DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0db51d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a7682828c94b999c40e0ef57af95a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9e63b1c93d481dbc401476aa3395a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7480edc6036e423f8041f47d828f8dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed18f3072f04ca0bf0f36da890fb24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6764a3f912de4d248ae7123b38d8a6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfa52c29e254fdcbff9ebbe908b80c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e1b21a0e4c45429a130ae599e39414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abea745f0f88419eade0d341d6c6ac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02925e3c57543bfbcf7f58e702aa107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19db2a8c953e4dfa91682c81d8dee711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453a3b59013446ec96ccb6934fcb6b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset=train_data,\n",
    "                        batch_size=256,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True)\n",
    "dataloader_valid = DataLoader(dataset=valid_data,\n",
    "                              batch_size=256,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "mlflow.set_experiment(\"ClassifierB\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_name\", \"RNN_based\")\n",
    "    mlflow.log_params({\n",
    "        \"embedding\": 'glove50d',\n",
    "    })\n",
    "    # instanciate model\n",
    "    model = QtypeClassifierB(emb_matrix)\n",
    "    model.cuda()\n",
    "    model = DataParallel(model)\n",
    "    lossfn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    for epoch in trange(5):\n",
    "        model.train()\n",
    "        running_loss = []\n",
    "        for idx, batch in enumerate(tqdm(dataloader)):\n",
    "            #if idx > 5:\n",
    "            #    break\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch[\"question\"])\n",
    "            loss_value = lossfn(output, batch[\"qtype\"].float().cuda())\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss_value.item())        \n",
    "        mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for idx, batch in enumerate(tqdm(dataloader_valid)):\n",
    "            #if idx > 5:\n",
    "            #    break\n",
    "            output = model(batch[\"question\"])\n",
    "            running_loss.append(\n",
    "                lossfn(output, batch[\"qtype\"].float().cuda()).item()\n",
    "            )\n",
    "            targets.extend(batch[\"qtype\"].numpy())\n",
    "            predictions.extend(output.squeeze().cpu().detach().numpy())\n",
    "        mlflow.log_metric(\"validation_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        mlflow.log_metric(\"validation_avp\", average_precision_score(targets, predictions), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43abbbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595ba08550d64f32820bc618e4684da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    question_ids = []\n",
    "    for batch in tqdm(dataloader_valid):\n",
    "        output = model(batch[\"question\"])\n",
    "        targets.extend(batch[\"qtype\"].float().cpu().numpy())\n",
    "        predictions.extend(output.squeeze().detach().cpu().numpy())\n",
    "        question_ids.extend(batch[\"qid\"].cpu().numpy())\n",
    "    pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(\n",
    "        f\"{tmpdirname}/predictions.csv.gz\", index=False\n",
    "    )\n",
    "    mlflow.log_artifact(f\"{tmpdirname}/predictions.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bdd70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'bin/gru_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91a24f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[1.96749647e-03 1.07740794e-04 7.28981046e-04 6.11157231e-02\n",
      " 1.74934219e-03 4.88175005e-01 7.56054127e-04 7.72921994e-05]\n"
     ]
    }
   ],
   "source": [
    "at = targets[0]\n",
    "pt = predictions[0]\n",
    "print(targets[0])\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae2b9f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(at, pt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
